Gradient descent is a method to find the minimum of a function, it can be applied to functions with multiple dimensions. But let's look at the example of just one dimension. In this video we will review: What's Gradient Descent, Problems with the Learning Rate, When to Stop Gradient Descent. What's Gradient Descent. Gradient descent is a method to find the minimum of a function. Consider the loss function, if we start off with a random guess for the slope parameter, we use the super script to indicate the guess number In this case it is our first guess so it is zero, we have to move our guess in the positive direction. We can move the slope in that direction by adding a positive number, examining the sign of of the derivative it is the opposite sign of the number. Therefore we can add a number proportional to the negative of the slope. Subtracting the derivative works if we are on the other side of the minimum. In this case, we would like to move in the negative direction We can move the parameter value to the negative direction by adding a negative number to the parameter. Examining the sine of the derivative, it is the opposite sine of the number. Therefore we can add an amount proportional to the negative of the derivative. In Gradient descent we iteratively calculate this equation, we start off with a guess, we update the parameter by adding a value proportional  to the derivative. We update the parameter again We can express the process as follows the parameter eta is the learning rate and tells us how much we need to jump. Let us clarify the process with an example. We start off with a guess of -4. The value for the derivative  at -4 is -112. We will use the following value for the learning rate. We calculate the first iteration, the value of the parameter for the first  iteration is -1.20. The value for this parameter has a smaller loss, we can see the loss is lower after the first iteration. For the next iterations, we use the previous parameter estimate of -1.2. We update the parameter value using the update rule The value for the parameter  is now -0.64, the loss function is closer  to the minimum, the loss value continues to get smaller. Let's see problems with the learning rate. If we chose a learning rate thatâ€™s toobig, sometimes we miss the minimum. Let's say we use a learning rate of 1 over 5, we update the parameter value using the update rule. The value for the parameter  is now -3.28, the loss function now has a higher value, now the loss value gets larger. Sometimes we can set the learning rate too small, let's see what happens when we set the learning rate to 1/240. For every iteration the value of the parameter hardly changes. In this case it will take a lot of iterations to reach the minimum value. We will learn how to select the learning rate. There are several ways to stop the process of gradient descent. Let's go over a few popular ways when to stop Gradient Descent. We can run gradient descent, for a set number of iterations is a popular way, in this case we run it for 3 iterations. But for the final iteration we miss the minimum. Another method to stop gradient descent is to see if the loss starts increasing, Let's record a few iterations of gradient descent and record the results in the table. For the first value, the loss is 250. We calculate the first iteration, we see the loss for this iteration is 150 less than the previous iteration. For the second iteration, the loss is also decreasing, we repeat the process. Examining the table we see the loss is 50 and still decreasing, so we keep going. The loss is now 100, this value is larger than 50 so we stop, We use the value of the parameter corresponding to loss of 50, the value is approximately - 2.5. You will learn more about gradient descent through out the course.